# DEFAULTS:
REPEAT: 1
GLOBAL_REPEAT: 1
name: skip # with default name=skip, training will be skipped if no name is specified
precision: 16 # 16 or anything else for default 32
directory: temp/1205_tests
full_path: exec f"{directory}/{name}/{IDX}"
checkpoint: exec f"{directory}/{name}/{IDX}.h5"
queue: null # specify path for queue file, if null keeps queue in memory

pruning: none # none|random|l1|snip|grasp + shuffle weight|layer|mask
pruning_config:
    structure: false # true for classic structural pruning | int N for enforcing N gorups
    sparsity: 0

dataset: cifar10 # mnist|cifar10 available
model: lenet
model_config:
    input_shape: [28, 28, 1]
    layer_sizes: [400, 400, 400]
    n_classes: 10
    l2_reg: 1e-4

lr_boundaries: [6000, 12000]
lr_values: [0.1, 0.01, 0.001]
num_iterations: 18000
steps_per_epoch: 2000

# EXPERIMENTS:
---
name: VGG19_lottery_random

model: VGG
model_config:
    version: 19
    input_shape: [32, 32, 3]
    n_classes: 10
    l2_reg: 1e-4

checkpointBP: data/VGG19_IMP03_ticket/95871/9.h5
checkpointAP: random

pruning: magnitude
pruning_config:
    sparsity: 0.986158712799

lr_boundaries: [32000, 48000, 64000]
lr_values: [0.1, 0.02, 0.004, 0.0008]
num_iterations: 80000
steps_per_epoch: 2000


#---
#name: VGG19_iterative_truning
#
#model: VGG
#model_config:
#    version: 19
#    input_shape: [32, 32, 3]
#    n_classes: 10
#    l2_reg: 1e-4
#
#lr_boundaries: [32000, 48000, 64000]
#lr_values: [0.1, 0.02, 0.004, 0.0008]
#num_iterations: 400
#steps_per_epoch: 2000
#---
#name: VGG19_iterative_truning
#
#model: VGG
#model_config:
#    version: 19
#    input_shape: [32, 32, 3]
#    n_classes: 10
#    l2_reg: 1e-4
#
#checkpointBP: checkpoint[-1]
#
#lr_boundaries: [32000, 48000, 64000]
#lr_values: [0.1, 0.02, 0.004, 0.0008]
#num_iterations: 80000
#steps_per_epoch: 2000
#---
#name: VGG19_iterative_truning
#
#model: VGG
#model_config:
#    version: 19
#    input_shape: [32, 32, 3]
#    n_classes: 10
#    l2_reg: 1e-4
#
#checkpointBP: checkpoint[-1]
#checkpointAP: checkpoint[0]
#
#pruning: trune
#pruning_config:
#    learning_rate: 10
#    momentum: 0.999
#    weight_decay: 1e-7
#    num_iterations: 16000
#    steps_per_epoch: 2000
#
#lr_boundaries: [32000, 48000, 64000]
#lr_values: [0.1, 0.02, 0.004, 0.0008]
#num_iterations: 80000
#steps_per_epoch: 2000
#REPEAT: 10
