{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#default_exp modules/tf_helper/training_functools.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training functools\n",
    "\n",
    "This module provides custom training functions for tensorflow training. Those tends to be a tad faster than keras built-in counterparts, probably due to smaller overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y, model):\n",
    "    assert isinstance(model, tf.keras.Model)\n",
    "    assert model.optimizer is not None, \"Model not compiled!\"\n",
    "    assert model.loss is not None, \"Model not compiled!\"\n",
    "    mixed_precision = isinstance(\n",
    "        model.optimizer, tf.keras.mixed_precision.experimental.LossScaleOptimizer\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        outs = model(x, training=True)\n",
    "        outs = tf.cast(outs, tf.float32)\n",
    "        loss = model.compiled_loss(y, outs, regularization_losses=model.losses)\n",
    "        if mixed_precision:\n",
    "            loss = model.optimizer.get_scaled_loss(loss)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    if mixed_precision:\n",
    "        gradients = model.optimizer.get_unscaled_gradients(gradients)\n",
    "\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    model.compiled_metrics.update_state(y, outs)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_step` is a lowest level function for training the model. Because it is decorated with `@tf.function`, `assert` statemets should not be executed during the runtime -- but only during the tracing. This is great, because it provides necessary testing without slowing down the runtime. This implementation provides mixed precision support -- also without slowing down the runtime in case if mixed precision is not used. Here is a minimal example of model training that demonstrates decaying loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34;1m# UNKNOWN CMD ARGUMENTS: ['-f', 'C:\\\\Users\\\\gaha\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-679624c9-fbbd-4148-b592-cc75a6994f68.json']\u001B[0m\n",
      "\u001B[34;1m#   KNOWN CMD ARGUMENTS: {'gpu': None, 'no_memory_growth': False}\u001B[0m\n",
      "\u001B[34;1m# SETTING MEMORY GROWTH!\u001B[0m\n",
      "\u001B[34;1m# ResNet: unknown parameters: []\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad29ae2a4ef44f4496abeac5fbd96f45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.tf_helper.models import VGG, WRN\n",
    "from modules.tf_helper.datasets import cifar\n",
    "from itertools import islice\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# model = VGG((32, 32, 3), 10, version=11)\n",
    "model = WRN(16, 8, (32, 32, 3), 10)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')],\n",
    ")\n",
    "data = cifar(shuffle_train=False)\n",
    "\n",
    "losses = []\n",
    "accurs = []\n",
    "for x, y in tqdm(islice(data['train'], 100), total=100):\n",
    "    outs = train_step(x, y, model)\n",
    "    losses.append(model.metrics[0].result())\n",
    "    accurs.append(model.metrics[1].result())\n",
    "    for metric in model.metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.subplot(212)\n",
    "plt.plot(range(len(accurs)), accurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above we train the network for 100 iterations. The loss should start going down and accuracy should start raising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def train_epoch(iterator, model, epoch_idx=0, steps=None, callbacks=(), use_pbar=None):\n",
    "    for callback in callbacks:\n",
    "        assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "        callback.on_epoch_begin(epoch_idx)\n",
    "\n",
    "    if use_pbar:\n",
    "        pbar = use_pbar\n",
    "    else:\n",
    "        pbar = tqdm(total=steps, leave=True, ascii=True)\n",
    "\n",
    "    for bidx, (x, y) in enumerate(islice(iterator, steps)):\n",
    "        for callback in callbacks:\n",
    "            assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "            callback.on_train_batch_begin(bidx)\n",
    "\n",
    "        outs = train_step(x, y, model)\n",
    "        pbar.set_postfix(\n",
    "            {m.name: m.result().numpy() for m in model.metrics}, refresh=False\n",
    "        )\n",
    "\n",
    "        for callback in callbacks:\n",
    "            assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "            callback.on_train_batch_end(bidx)\n",
    "        pbar.update()\n",
    "\n",
    "    if not use_pbar:\n",
    "        pbar.close()\n",
    "\n",
    "    for callback in callbacks:\n",
    "        assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "        callback.on_epoch_end(epoch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 13.22787880897522\n",
      "loss = 3.7753608226776123\n",
      "accuracy = 0.4429687559604645\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "train_epoch(\n",
    "    data[\"train\"], model, steps=100, callbacks=[tf.keras.callbacks.Callback()]\n",
    ")\n",
    "print(f\"TIME: {time.time() - t0}\")\n",
    "\n",
    "for metric in model.metrics:\n",
    "    print(f\"{metric.name} = {metric.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@tf.function\n",
    "def valid_step(x, y, model):\n",
    "    assert isinstance(model, tf.keras.Model)\n",
    "    assert model.loss is not None, \"Model not compiled!\"\n",
    "\n",
    "    outs = model(x, training=False)\n",
    "    outs = tf.cast(outs, tf.float32)\n",
    "    model.compiled_loss(y, outs)\n",
    "    model.compiled_metrics.update_state(y, outs)\n",
    "    return outs\n",
    "\n",
    "\n",
    "def valid_epoch(iterator, model, epoch_idx=0, steps=None, callbacks=()):\n",
    "    for bidx, (x, y) in enumerate(islice(iterator, steps)):\n",
    "        for callback in callbacks:\n",
    "            assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "            callback.on_test_batch_begin(bidx)\n",
    "\n",
    "        outs = valid_step(x, y, model)\n",
    "\n",
    "        for callback in callbacks:\n",
    "            assert isinstance(callback, tf.keras.callbacks.Callback)\n",
    "            callback.on_test_batch_end(bidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.009577512741089\n",
      "accuracy: 0.4010087847709656\n"
     ]
    }
   ],
   "source": [
    "valid_epoch(data[\"test\"], model)\n",
    "for m in model.metrics:\n",
    "    print(f\"{m.name}: {m.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def reset_metrics(model):\n",
    "    results = {m.name: m.result().numpy() for m in model.metrics}\n",
    "    for metric in model.metrics:\n",
    "        metric.reset_states()\n",
    "    return results\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model,\n",
    "    training_data,\n",
    "    validation_data,\n",
    "    steps_per_epoch=None,\n",
    "    epochs=1,\n",
    "    initial_epoch=0,\n",
    "    callbacks=(),\n",
    "):\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    bpbar = tqdm(total=epochs, leave=True, ascii=True)\n",
    "    for epoch_idx in range(initial_epoch, epochs):\n",
    "        pbar = tqdm(total=steps_per_epoch, leave=True, ascii=True)\n",
    "        train_epoch(\n",
    "            training_data,\n",
    "            model,\n",
    "            epoch_idx=epoch_idx,\n",
    "            steps=steps_per_epoch,\n",
    "            callbacks=callbacks,\n",
    "            use_pbar=pbar,\n",
    "        )\n",
    "        metrics = reset_metrics(model)\n",
    "        for key, value in metrics.items():\n",
    "            history[key].append(value)\n",
    "\n",
    "        valid_epoch(\n",
    "            validation_data,\n",
    "            model,\n",
    "            epoch_idx=epoch_idx,\n",
    "            steps=steps_per_epoch,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        metrics = reset_metrics(model)\n",
    "        for key, value in metrics.items():\n",
    "            history[\"val_\" + key].append(value)\n",
    "\n",
    "        metrics = reset_metrics(model)\n",
    "\n",
    "        pbar.close()\n",
    "        bpbar.set_postfix({key: value[-1] for key, value in history.items()})\n",
    "        bpbar.update()\n",
    "    return dict(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92aaca7904584873b0b1b54a1398ce64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66812aba14cf4b7b95934e8f18069f40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6655c32c6df64dfaae5e55f368ad14d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fae5d35a1a1b4c8d9a978e306c469c9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70cec3b9be00416b9b05852ef1c09ff4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0daf3c4e5e2145839c316f4384373dca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'loss': [3.0393364, 3.4806876, 3.415501, 3.3726249, 3.2958267],\n 'accuracy': [0.40502492, 0.521875, 0.5210937, 0.553125, 0.5546875],\n 'val_loss': [1.8310251, 1.4278662, 1.6661994, 1.7883714, 1.638818],\n 'val_accuracy': [0.38632813, 0.5001953, 0.41308594, 0.39648438, 0.43046874]}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, data[\"train\"], data[\"test\"], steps_per_epoch=10, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating modules\\tf_helper\\training_functools.py\n"
     ]
    }
   ],
   "source": [
    "%run convert_notebooks.py"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55e71a62cc267b8a0bae4b336a38f88abe99825cae755cc76843f5de83cc683c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}